{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMxDK1utNOJZ8ySJ8fdRhBY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7__Kw820Q51U","executionInfo":{"status":"ok","timestamp":1729785811315,"user_tz":-180,"elapsed":25740,"user":{"displayName":"Abdulvahap Mutlu","userId":"04445952924936781568"}},"outputId":"399addec-333d-4214-cd01-5d15630e6b48"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from scipy.signal import periodogram, resample\n","import wfdb\n","from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt  # Optional, for visualization\n","import pickle  # For saving loss history and models\n","\n","# ===========================\n","# Set Seed for Reproducibility\n","# ===========================\n","def set_seed(seed=0):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","set_seed(0)\n","\n","# ===========================\n","# Configuration\n","# ===========================\n","DATASET_PATH = \"/content/drive/My Drive/mit-bih-arrhythmia-database-1.0.0\"\n","SAMPLE_RATE = 360  # Original sampling rate for MIT-BIH\n","TARGET_SAMPLE_RATE = 64  # Downsampled rate as per user's code\n","\n","# Updated Window Size: 3.0 seconds to match kernel size of 192\n","WINDOW_SIZE_SEC = 3.0  # Window size in seconds around R-peak\n","WINDOW_SIZE = int(WINDOW_SIZE_SEC * TARGET_SAMPLE_RATE)  # 192 samples\n","\n","OVERLAP = 0  # No overlap\n","NUM_SPLITS = 10\n","DATA_FRACTION = 1.0\n","NUM_KERNELS = 128\n","LEARNING_RATE = 0.001\n","BATCH_SIZE = 256\n","NUM_EPOCHS = 16\n","END_FACTOR = 0.1\n","USE_TQDM = False  # Disable tqdm during training\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# ===========================\n","# Utility Functions\n","# ===========================\n","\n","def load_record(record_name, path, target_fs=TARGET_SAMPLE_RATE):\n","    \"\"\"\n","    Load a single record, resample, and extract R-peaks and annotations.\n","    \"\"\"\n","    record = wfdb.rdrecord(os.path.join(path, record_name))\n","    annotation = wfdb.rdann(os.path.join(path, record_name), 'atr')\n","\n","    # Select first channel (usually MLII)\n","    signal = record.p_signal[:,0]\n","\n","    # Resample signal\n","    num_samples = int(len(signal) * target_fs / SAMPLE_RATE)\n","    signal_resampled = resample(signal, num_samples)\n","\n","    # Adjust R-peak locations after resampling\n","    r_peaks = (annotation.sample * target_fs) // SAMPLE_RATE\n","    r_peaks = r_peaks[r_peaks < len(signal_resampled)]\n","\n","    # Extract annotations\n","    annotations = annotation.symbol\n","    return signal_resampled, r_peaks, annotations\n","\n","def extract_windows(signal, r_peaks, annotations, window_size=WINDOW_SIZE):\n","    \"\"\"\n","    Extract windows around R-peaks and assign labels.\n","    \"\"\"\n","    half_window = window_size // 2\n","    windows = []\n","    labels = []\n","\n","    for peak, symbol in zip(r_peaks, annotations):\n","        start = peak - half_window\n","        end = peak + half_window\n","        if start < 0 or end > len(signal):\n","            continue  # Skip if window is out of bounds\n","        window = signal[start:end]\n","        windows.append(window)\n","        labels.append(symbol)\n","    return np.array(windows), np.array(labels)\n","\n","def map_labels(labels):\n","    \"\"\"\n","    Map original MIT-BIH labels to desired classes:\n","    - \"Normal\" (N, L, R, e, j)\n","    - \"Afib\" (A, a, F, J, S)\n","    - \"Other\" (all other classes)\n","    \"\"\"\n","    normal = ['N', 'L', 'R', 'e', 'j']  # Including some variants\n","    afib = ['A', 'a', 'F', 'J', 'S']\n","    mapped_labels = []\n","    for label in labels:\n","        if label in normal:\n","            mapped_labels.append(0)  # Normal\n","        elif label in afib:\n","            mapped_labels.append(1)  # Afib\n","        else:\n","            mapped_labels.append(2)  # Other\n","    return np.array(mapped_labels)\n","\n","def load_dataset(path):\n","    \"\"\"\n","    Load all records, extract windows and labels.\n","    \"\"\"\n","    # List of all record names in the dataset\n","    records = [f.split('.')[0] for f in os.listdir(path) if f.endswith('.dat')]\n","\n","    all_windows = []\n","    all_labels = []\n","\n","    for record in tqdm(records, desc=\"Loading Records\"):\n","        signal, r_peaks, annotations = load_record(record, path)\n","        windows, labels = extract_windows(signal, r_peaks, annotations)\n","        windows = windows[:, :WINDOW_SIZE]  # Ensure consistent window size\n","        all_windows.append(windows)\n","        all_labels.append(labels)\n","\n","    all_windows = np.concatenate(all_windows, axis=0)\n","    all_labels = np.concatenate(all_labels, axis=0)\n","    mapped_labels = map_labels(all_labels)\n","\n","    # Exclude \"Other\" class if needed\n","    # For demonstration, we'll keep all classes\n","    return all_windows, mapped_labels\n","\n","def generate_splits(X, Y, num_splits=NUM_SPLITS):\n","    \"\"\"\n","    Generate cross-validation splits.\n","    \"\"\"\n","    splits = []\n","    unique_classes = np.unique(Y)\n","    for split in range(num_splits):\n","        # Simple random split; for better stratification, implement stratified splits\n","        indices = np.arange(len(X))\n","        np.random.shuffle(indices)\n","        train_size = int(0.8 * len(X))\n","        train_idx = indices[:train_size]\n","        test_idx = indices[train_size:]\n","        splits.append((train_idx, test_idx))\n","    return splits\n","\n","def calculate_metrics(y_true, y_prob, num_classes=3):\n","    \"\"\"\n","    Calculate sensitivity, specificity, AUC, and F1 scores.\n","    \"\"\"\n","    y_pred = np.argmax(y_prob, axis=1)\n","    sensitivities = []\n","    specificities = []\n","    AUCs = []\n","    F1s = []\n","\n","    for cls in range(num_classes):\n","        # Binary labels for the current class\n","        true_binary = (y_true == cls).astype(int)\n","        pred_binary = (y_pred == cls).astype(int)\n","\n","        # Compute confusion matrix\n","        cm = confusion_matrix(true_binary, pred_binary).ravel()\n","        if len(cm) == 4:\n","            tn, fp, fn, tp = cm\n","        elif len(cm) == 2:\n","            tn, tp = cm\n","            fp, fn = 0, 0\n","        elif len(cm) == 1:\n","            tp = cm[0]\n","            tn, fp, fn = 0, 0, 0\n","        else:\n","            tn, fp, fn, tp = 0, 0, 0, 0\n","\n","        # Sensitivity (Recall)\n","        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n","        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n","        sensitivities.append(sensitivity)\n","        specificities.append(specificity)\n","\n","        # AUC\n","        try:\n","            auc = roc_auc_score(true_binary, y_prob[:, cls])\n","        except ValueError:\n","            auc = 0  # If only one class is present in y_true, AUC is not defined\n","        AUCs.append(auc)\n","\n","        # F1 Score\n","        f1 = f1_score(true_binary, pred_binary, zero_division=0)\n","        F1s.append(f1)\n","\n","    return sensitivities, specificities, AUCs, F1s\n","\n","def print_table(sensitivities, specificities, AUCs, class_names):\n","    \"\"\"\n","    Print a table of metrics.\n","    \"\"\"\n","    print(f\"{'Class':<10}{'Sensitivity':<15}{'Specificity':<15}{'AUC':<10}\")\n","    for i, class_name in enumerate(class_names):\n","        print(f\"{class_name:<10}{sensitivities[i]:<15.3f}{specificities[i]:<15.3f}{AUCs[i]:<10.3f}\")\n","\n","# ===========================\n","# Dataset Class\n","# ===========================\n","from torch.utils.data import Dataset, DataLoader\n","\n","class ArrhythmiaDataset(Dataset):\n","    def __init__(self, X, Y):\n","        self.X = torch.tensor(X, dtype=torch.float32)\n","        self.Y = torch.tensor(Y, dtype=torch.long)\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.Y[idx]\n","\n","# ===========================\n","# Model Definition\n","# ===========================\n","\n","class LearnedFilters(nn.Module):\n","    \"\"\"\n","    SMoLK Model: Learned Filters for Arrhythmia Classification\n","\n","    This model applies multiple convolutional filters of varying kernel sizes\n","    to the input signal, extracts features by averaging the activations, and\n","    combines them with power spectrum features for classification.\n","    \"\"\"\n","    def __init__(self, num_kernels=24, num_classes=3):\n","        super(LearnedFilters, self).__init__()\n","        self.conv1 = nn.Conv1d(1, num_kernels, 192, stride=1, bias=True)\n","        self.conv2 = nn.Conv1d(1, num_kernels, 96, stride=1, bias=True)\n","        self.conv3 = nn.Conv1d(1, num_kernels, 64, stride=1, bias=True)\n","        self.linear = nn.Linear(num_kernels*3 + 321, num_classes)  # 321 is the size of the power spectrum\n","\n","    def forward(self, x, powerspectrum):\n","        c1 = F.leaky_relu(self.conv1(x)).mean(dim=-1)\n","        c2 = F.leaky_relu(self.conv2(x)).mean(dim=-1)\n","        c3 = F.leaky_relu(self.conv3(x)).mean(dim=-1)\n","        aggregate = torch.cat([c1, c2, c3, powerspectrum], dim=1)\n","        aggregate = self.linear(aggregate)\n","        return aggregate\n","\n","# ===========================\n","# Training and Testing Functions\n","# ===========================\n","\n","def compute_power_spectra(X_batch):\n","    \"\"\"\n","    Compute power spectra for a batch of samples using periodogram.\n","    \"\"\"\n","    PowerSpectra = []\n","    for i in range(len(X_batch)):\n","        f, Pxx = periodogram(X_batch[i], fs=TARGET_SAMPLE_RATE)\n","        # To match size 321, interpolate or truncate\n","        if len(Pxx) < 321:\n","            Pxx = np.pad(Pxx, (0, 321 - len(Pxx)), 'constant')\n","        else:\n","            Pxx = Pxx[:321]\n","        PowerSpectra.append(Pxx)\n","    return np.array(PowerSpectra).astype(np.float32)\n","\n","def train_model(model, optimizer, scheduler, criterion, dataloader, device):\n","    \"\"\"\n","    Train the model for one epoch.\n","    \"\"\"\n","    model.train()\n","    running_loss = 0.0\n","    for data, target in dataloader:\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        # Compute power spectra\n","        powerspectrum = compute_power_spectra(data.cpu().numpy())\n","        powerspectrum = torch.tensor(powerspectrum, dtype=torch.float32).to(device)\n","        data = data.unsqueeze(1)  # Add channel dimension\n","        output = model(data, powerspectrum)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        running_loss += loss.item() * data.size(0)\n","    epoch_loss = running_loss / len(dataloader.dataset)\n","    return epoch_loss\n","\n","def evaluate_model(model, dataloader, device):\n","    \"\"\"\n","    Evaluate the model and return probabilities and ground truth.\n","    \"\"\"\n","    model.eval()\n","    probs = []\n","    ground_truth = []\n","    with torch.no_grad():\n","        for data, target in dataloader:\n","            data, target = data.to(device), target.to(device)\n","            powerspectrum = compute_power_spectra(data.cpu().numpy())\n","            powerspectrum = torch.tensor(powerspectrum, dtype=torch.float32).to(device)\n","            data = data.unsqueeze(1)  # Add channel dimension\n","            output = model(data, powerspectrum).softmax(dim=-1)\n","            probs.append(output.cpu().numpy())\n","            ground_truth.append(target.cpu().numpy())\n","    probs = np.concatenate(probs, axis=0)\n","    ground_truth = np.concatenate(ground_truth, axis=0)\n","    return probs, ground_truth\n","\n","# ===========================\n","# Main Execution\n","# ===========================\n","\n","def main():\n","    # Create directories to save models and loss history\n","    os.makedirs(\"saved_models\", exist_ok=True)\n","    os.makedirs(\"loss_history\", exist_ok=True)\n","\n","    # Load and preprocess the dataset\n","    print(\"Loading and preprocessing the dataset...\")\n","    X, Y = load_dataset(DATASET_PATH)\n","    print(f\"Total samples: {len(X)}\")\n","    print(f\"Class distribution: {np.bincount(Y)}\")\n","\n","    # Generate cross-validation splits\n","    splits = generate_splits(X, Y, NUM_SPLITS)\n","\n","    models = []\n","    loss_histories = []\n","    for split in range(NUM_SPLITS):\n","        print(f\"\\n=== Split {split + 1}/{NUM_SPLITS} ===\")\n","        train_idx, test_idx = splits[split]\n","        X_train, Y_train = X[train_idx], Y[train_idx]\n","        X_test, Y_test = X[test_idx], Y[test_idx]\n","\n","        # Shuffle training data\n","        p = np.random.permutation(len(X_train))\n","        X_train, Y_train = X_train[p], Y_train[p]\n","\n","        # Use data fraction\n","        X_train = X_train[:int(DATA_FRACTION * len(X_train))]\n","        Y_train = Y_train[:int(DATA_FRACTION * len(Y_train))]\n","\n","        # Compute class weights\n","        class_counts = np.bincount(Y_train)\n","        class_weights = 1. / class_counts\n","        class_weights = class_weights / class_weights.sum()\n","        class_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n","\n","        # Create DataLoader\n","        train_dataset = ArrhythmiaDataset(X_train, Y_train)\n","        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","        # Initialize the model\n","        model = LearnedFilters(num_kernels=NUM_KERNELS, num_classes=3).to(DEVICE)\n","\n","        # Define optimizer, scheduler, and loss function\n","        optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n","        scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=END_FACTOR, total_iters=NUM_EPOCHS*len(train_loader))\n","        criterion = nn.CrossEntropyLoss(weight=class_weights)\n","\n","        # Training loop\n","        loss_history = []\n","        for epoch in range(NUM_EPOCHS):\n","            print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}\")\n","            epoch_loss = train_model(model, optimizer, scheduler, criterion, train_loader, DEVICE)\n","            loss_history.append(epoch_loss)\n","            if not USE_TQDM:\n","                print(f\"Epoch Loss: {epoch_loss:.4f}\")\n","\n","        # Append the trained model and loss history\n","        models.append(model)\n","        loss_histories.append(loss_history)\n","\n","        # Save the trained model\n","        model_path = f\"saved_models/model_split_{split+1}.pt\"\n","        torch.save(model.state_dict(), model_path)\n","        print(f\"Saved model to {model_path}\")\n","\n","        # Save the loss history\n","        loss_path = f\"loss_history/loss_split_{split+1}.pkl\"\n","        with open(loss_path, 'wb') as f:\n","            pickle.dump(loss_history, f)\n","        print(f\"Saved loss history to {loss_path}\")\n","\n","    # Cross-Validation Evaluation\n","    print(\"\\n=== Cross-Validation Evaluation ===\")\n","    sensitivities = []\n","    specificities = []\n","    AUCs = []\n","    F1s = []\n","    class_names = [\"Normal\", \"Afib\", \"Other\"]\n","\n","    for split in range(NUM_SPLITS):\n","        print(f\"\\n--- Evaluating Split {split + 1} ---\")\n","        train_idx, test_idx = splits[split]\n","        X_test, Y_test = X[test_idx], Y[test_idx]\n","\n","        test_dataset = ArrhythmiaDataset(X_test, Y_test)\n","        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","        model = models[split]\n","        model_path = f\"saved_models/model_split_{split+1}.pt\"\n","        model.load_state_dict(torch.load(model_path))\n","        model.to(DEVICE)\n","\n","        probs, ground_truth = evaluate_model(model, test_loader, DEVICE)\n","\n","        sen, spec, auc, f1 = calculate_metrics(ground_truth, probs, num_classes=3)\n","        sensitivities.append(sen)\n","        specificities.append(spec)\n","        AUCs.append(auc)\n","        F1s.append(f1)\n","\n","    sensitivities = np.array(sensitivities)\n","    specificities = np.array(specificities)\n","    AUCs = np.array(AUCs)\n","    F1s = np.array(F1s)\n","\n","    print(\"\\n=== Cross-Validation Results ===\")\n","    print_table(sensitivities.mean(axis=0), specificities.mean(axis=0), AUCs.mean(axis=0), class_names)\n","    print(f\"F1 Score: {F1s.mean():.3f} ± {F1s.std():.3f}\")\n","\n","    # ===========================\n","    # Holdout Set Evaluation\n","    # ===========================\n","    print(\"\\n=== Holdout Set Evaluation ===\")\n","    # For demonstration, we'll use the last split as holdout\n","    holdout_split = NUM_SPLITS - 1\n","    train_idx, holdout_idx = splits[holdout_split]\n","    X_holdout, Y_holdout = X[holdout_idx], Y[holdout_idx]\n","    holdout_dataset = ArrhythmiaDataset(X_holdout, Y_holdout)\n","    holdout_loader = DataLoader(holdout_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","    probs = []\n","    ground_truth = []\n","    for split in range(NUM_SPLITS):\n","        print(f\"\\n--- Evaluating Model {split + 1} on Holdout Set ---\")\n","        model = models[split]\n","        model_path = f\"saved_models/model_split_{split+1}.pt\"\n","        model.load_state_dict(torch.load(model_path))\n","        model.to(DEVICE)\n","\n","        prob, gt = evaluate_model(model, holdout_loader, DEVICE)\n","        probs.append(prob)\n","        ground_truth.append(gt)\n","\n","    sensitivities = []\n","    specificities = []\n","    AUCs = []\n","    F1s = []\n","\n","    for split in range(NUM_SPLITS):\n","        sen, spec, auc, f1 = calculate_metrics(ground_truth[split], probs[split], num_classes=3)\n","        sensitivities.append(sen)\n","        specificities.append(spec)\n","        AUCs.append(auc)\n","        F1s.append(f1)\n","\n","    sensitivities = np.array(sensitivities)\n","    specificities = np.array(specificities)\n","    AUCs = np.array(AUCs)\n","    F1s = np.array(F1s)\n","\n","    print(\"\\n=== Holdout Set Results ===\")\n","    print_table(sensitivities.mean(axis=0), specificities.mean(axis=0), AUCs.mean(axis=0), class_names)\n","    print(f\"F1 Score: {F1s.mean():.3f} ± {F1s.std():.3f}\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fZFdXgX4RGrl","executionInfo":{"status":"ok","timestamp":1729791525769,"user_tz":-180,"elapsed":5259653,"user":{"displayName":"Abdulvahap Mutlu","userId":"04445952924936781568"}},"outputId":"e36a2219-229f-462c-a5b4-bcdf83268cf6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading and preprocessing the dataset...\n"]},{"output_type":"stream","name":"stderr","text":["Loading Records: 100%|██████████| 48/48 [00:07<00:00,  6.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Total samples: 112419\n","Class distribution: [90477  3581 18361]\n","\n","=== Split 1/10 ===\n","Epoch 1/16\n","Epoch Loss: 0.6057\n","Epoch 2/16\n","Epoch Loss: 0.4054\n","Epoch 3/16\n","Epoch Loss: 0.3383\n","Epoch 4/16\n","Epoch Loss: 0.2988\n","Epoch 5/16\n","Epoch Loss: 0.2705\n","Epoch 6/16\n","Epoch Loss: 0.2490\n","Epoch 7/16\n","Epoch Loss: 0.2333\n","Epoch 8/16\n","Epoch Loss: 0.2168\n","Epoch 9/16\n","Epoch Loss: 0.2056\n","Epoch 10/16\n","Epoch Loss: 0.1927\n","Epoch 11/16\n","Epoch Loss: 0.1822\n","Epoch 12/16\n","Epoch Loss: 0.1756\n","Epoch 13/16\n","Epoch Loss: 0.1679\n","Epoch 14/16\n","Epoch Loss: 0.1614\n","Epoch 15/16\n","Epoch Loss: 0.1571\n","Epoch 16/16\n","Epoch Loss: 0.1536\n","Saved model to saved_models/model_split_1.pt\n","Saved loss history to loss_history/loss_split_1.pkl\n","\n","=== Split 2/10 ===\n","Epoch 1/16\n","Epoch Loss: 0.6148\n","Epoch 2/16\n","Epoch Loss: 0.4056\n","Epoch 3/16\n","Epoch Loss: 0.3356\n","Epoch 4/16\n","Epoch Loss: 0.2984\n","Epoch 5/16\n","Epoch Loss: 0.2689\n","Epoch 6/16\n","Epoch Loss: 0.2471\n","Epoch 7/16\n","Epoch Loss: 0.2350\n","Epoch 8/16\n","Epoch Loss: 0.2177\n","Epoch 9/16\n","Epoch Loss: 0.2049\n","Epoch 10/16\n","Epoch Loss: 0.1965\n","Epoch 11/16\n","Epoch Loss: 0.1881\n","Epoch 12/16\n","Epoch Loss: 0.1775\n","Epoch 13/16\n","Epoch Loss: 0.1712\n","Epoch 14/16\n","Epoch Loss: 0.1667\n","Epoch 15/16\n","Epoch Loss: 0.1610\n","Epoch 16/16\n","Epoch Loss: 0.1573\n","Saved model to saved_models/model_split_2.pt\n","Saved loss history to loss_history/loss_split_2.pkl\n","\n","=== Split 3/10 ===\n","Epoch 1/16\n","Epoch Loss: 0.6153\n","Epoch 2/16\n","Epoch Loss: 0.4085\n","Epoch 3/16\n","Epoch Loss: 0.3426\n","Epoch 4/16\n","Epoch Loss: 0.3002\n","Epoch 5/16\n","Epoch Loss: 0.2761\n","Epoch 6/16\n","Epoch Loss: 0.2508\n","Epoch 7/16\n","Epoch Loss: 0.2352\n","Epoch 8/16\n","Epoch Loss: 0.2188\n","Epoch 9/16\n","Epoch Loss: 0.2037\n","Epoch 10/16\n","Epoch Loss: 0.1922\n","Epoch 11/16\n","Epoch Loss: 0.1815\n","Epoch 12/16\n","Epoch Loss: 0.1775\n","Epoch 13/16\n","Epoch Loss: 0.1674\n","Epoch 14/16\n","Epoch Loss: 0.1624\n","Epoch 15/16\n","Epoch Loss: 0.1569\n","Epoch 16/16\n","Epoch Loss: 0.1527\n","Saved model to saved_models/model_split_3.pt\n","Saved loss history to loss_history/loss_split_3.pkl\n","\n","=== Split 4/10 ===\n","Epoch 1/16\n","Epoch Loss: 0.6244\n","Epoch 2/16\n","Epoch Loss: 0.4182\n","Epoch 3/16\n","Epoch Loss: 0.3489\n","Epoch 4/16\n","Epoch Loss: 0.3118\n","Epoch 5/16\n","Epoch Loss: 0.2844\n","Epoch 6/16\n","Epoch Loss: 0.2629\n","Epoch 7/16\n","Epoch Loss: 0.2482\n","Epoch 8/16\n","Epoch Loss: 0.2293\n","Epoch 9/16\n","Epoch Loss: 0.2182\n","Epoch 10/16\n","Epoch Loss: 0.2059\n","Epoch 11/16\n","Epoch Loss: 0.1973\n","Epoch 12/16\n","Epoch Loss: 0.1891\n","Epoch 13/16\n","Epoch Loss: 0.1813\n","Epoch 14/16\n","Epoch Loss: 0.1738\n","Epoch 15/16\n","Epoch Loss: 0.1685\n","Epoch 16/16\n","Epoch Loss: 0.1653\n","Saved model to saved_models/model_split_4.pt\n","Saved loss history to loss_history/loss_split_4.pkl\n","\n","=== Split 5/10 ===\n","Epoch 1/16\n","Epoch Loss: 0.6195\n","Epoch 2/16\n","Epoch Loss: 0.4161\n","Epoch 3/16\n","Epoch Loss: 0.3472\n","Epoch 4/16\n","Epoch Loss: 0.3074\n","Epoch 5/16\n","Epoch Loss: 0.2790\n","Epoch 6/16\n","Epoch Loss: 0.2558\n","Epoch 7/16\n","Epoch Loss: 0.2403\n","Epoch 8/16\n","Epoch Loss: 0.2214\n","Epoch 9/16\n","Epoch Loss: 0.2101\n","Epoch 10/16\n","Epoch Loss: 0.1994\n","Epoch 11/16\n","Epoch Loss: 0.1872\n","Epoch 12/16\n","Epoch Loss: 0.1822\n","Epoch 13/16\n","Epoch Loss: 0.1740\n","Epoch 14/16\n","Epoch Loss: 0.1681\n","Epoch 15/16\n","Epoch Loss: 0.1633\n","Epoch 16/16\n","Epoch Loss: 0.1583\n","Saved model to saved_models/model_split_5.pt\n","Saved loss history to loss_history/loss_split_5.pkl\n","\n","=== Split 6/10 ===\n","Epoch 1/16\n","Epoch Loss: 0.6125\n","Epoch 2/16\n","Epoch Loss: 0.4070\n","Epoch 3/16\n","Epoch Loss: 0.3382\n","Epoch 4/16\n","Epoch Loss: 0.3034\n","Epoch 5/16\n","Epoch Loss: 0.2726\n","Epoch 6/16\n","Epoch Loss: 0.2504\n","Epoch 7/16\n","Epoch Loss: 0.2334\n","Epoch 8/16\n","Epoch Loss: 0.2163\n","Epoch 9/16\n","Epoch Loss: 0.2075\n","Epoch 10/16\n","Epoch Loss: 0.1983\n","Epoch 11/16\n","Epoch Loss: 0.1857\n","Epoch 12/16\n","Epoch Loss: 0.1780\n","Epoch 13/16\n","Epoch Loss: 0.1719\n","Epoch 14/16\n","Epoch Loss: 0.1669\n","Epoch 15/16\n","Epoch Loss: 0.1604\n","Epoch 16/16\n","Epoch Loss: 0.1563\n","Saved model to saved_models/model_split_6.pt\n","Saved loss history to loss_history/loss_split_6.pkl\n","\n","=== Split 7/10 ===\n","Epoch 1/16\n","Epoch Loss: 0.6139\n","Epoch 2/16\n","Epoch Loss: 0.4063\n","Epoch 3/16\n","Epoch Loss: 0.3388\n","Epoch 4/16\n","Epoch Loss: 0.2992\n","Epoch 5/16\n","Epoch Loss: 0.2703\n","Epoch 6/16\n","Epoch Loss: 0.2508\n","Epoch 7/16\n","Epoch Loss: 0.2321\n","Epoch 8/16\n","Epoch Loss: 0.2188\n","Epoch 9/16\n","Epoch Loss: 0.2028\n","Epoch 10/16\n","Epoch Loss: 0.1926\n","Epoch 11/16\n","Epoch Loss: 0.1820\n","Epoch 12/16\n","Epoch Loss: 0.1744\n","Epoch 13/16\n","Epoch Loss: 0.1684\n","Epoch 14/16\n","Epoch Loss: 0.1612\n","Epoch 15/16\n","Epoch Loss: 0.1567\n","Epoch 16/16\n","Epoch Loss: 0.1524\n","Saved model to saved_models/model_split_7.pt\n","Saved loss history to loss_history/loss_split_7.pkl\n","\n","=== Split 8/10 ===\n","Epoch 1/16\n","Epoch Loss: 0.6108\n","Epoch 2/16\n","Epoch Loss: 0.3977\n","Epoch 3/16\n","Epoch Loss: 0.3313\n","Epoch 4/16\n","Epoch Loss: 0.2970\n","Epoch 5/16\n","Epoch Loss: 0.2689\n","Epoch 6/16\n","Epoch Loss: 0.2455\n","Epoch 7/16\n","Epoch Loss: 0.2282\n","Epoch 8/16\n","Epoch Loss: 0.2153\n","Epoch 9/16\n","Epoch Loss: 0.2038\n","Epoch 10/16\n","Epoch Loss: 0.1921\n","Epoch 11/16\n","Epoch Loss: 0.1839\n","Epoch 12/16\n","Epoch Loss: 0.1738\n","Epoch 13/16\n","Epoch Loss: 0.1687\n","Epoch 14/16\n","Epoch Loss: 0.1621\n","Epoch 15/16\n","Epoch Loss: 0.1569\n","Epoch 16/16\n","Epoch Loss: 0.1533\n","Saved model to saved_models/model_split_8.pt\n","Saved loss history to loss_history/loss_split_8.pkl\n","\n","=== Split 9/10 ===\n","Epoch 1/16\n","Epoch Loss: 0.6133\n","Epoch 2/16\n","Epoch Loss: 0.4095\n","Epoch 3/16\n","Epoch Loss: 0.3452\n","Epoch 4/16\n","Epoch Loss: 0.3046\n","Epoch 5/16\n","Epoch Loss: 0.2782\n","Epoch 6/16\n","Epoch Loss: 0.2551\n","Epoch 7/16\n","Epoch Loss: 0.2396\n","Epoch 8/16\n","Epoch Loss: 0.2219\n","Epoch 9/16\n","Epoch Loss: 0.2093\n","Epoch 10/16\n","Epoch Loss: 0.1997\n","Epoch 11/16\n","Epoch Loss: 0.1867\n","Epoch 12/16\n","Epoch Loss: 0.1782\n","Epoch 13/16\n","Epoch Loss: 0.1721\n","Epoch 14/16\n","Epoch Loss: 0.1667\n","Epoch 15/16\n","Epoch Loss: 0.1599\n","Epoch 16/16\n","Epoch Loss: 0.1565\n","Saved model to saved_models/model_split_9.pt\n","Saved loss history to loss_history/loss_split_9.pkl\n","\n","=== Split 10/10 ===\n","Epoch 1/16\n","Epoch Loss: 0.6124\n","Epoch 2/16\n","Epoch Loss: 0.4039\n","Epoch 3/16\n","Epoch Loss: 0.3308\n","Epoch 4/16\n","Epoch Loss: 0.2955\n","Epoch 5/16\n","Epoch Loss: 0.2642\n","Epoch 6/16\n","Epoch Loss: 0.2417\n","Epoch 7/16\n","Epoch Loss: 0.2276\n","Epoch 8/16\n","Epoch Loss: 0.2106\n","Epoch 9/16\n","Epoch Loss: 0.1999\n","Epoch 10/16\n","Epoch Loss: 0.1880\n","Epoch 11/16\n","Epoch Loss: 0.1812\n","Epoch 12/16\n","Epoch Loss: 0.1720\n","Epoch 13/16\n","Epoch Loss: 0.1660\n","Epoch 14/16\n","Epoch Loss: 0.1601\n","Epoch 15/16\n","Epoch Loss: 0.1551\n","Epoch 16/16\n","Epoch Loss: 0.1518\n","Saved model to saved_models/model_split_10.pt\n","Saved loss history to loss_history/loss_split_10.pkl\n","\n","=== Cross-Validation Evaluation ===\n","\n","--- Evaluating Split 1 ---\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-7-2f9d46536ae3>:405: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(model_path))\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Evaluating Split 2 ---\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-7-2f9d46536ae3>:405: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(model_path))\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Evaluating Split 3 ---\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-7-2f9d46536ae3>:405: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(model_path))\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Evaluating Split 4 ---\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-7-2f9d46536ae3>:405: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(model_path))\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Evaluating Split 5 ---\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-7-2f9d46536ae3>:405: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(model_path))\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Evaluating Split 6 ---\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-7-2f9d46536ae3>:405: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(model_path))\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Evaluating Split 7 ---\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-7-2f9d46536ae3>:405: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(model_path))\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Evaluating Split 8 ---\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-7-2f9d46536ae3>:405: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(model_path))\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Evaluating Split 9 ---\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-7-2f9d46536ae3>:405: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(model_path))\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Evaluating Split 10 ---\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-7-2f9d46536ae3>:405: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(model_path))\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Cross-Validation Results ===\n","Class     Sensitivity    Specificity    AUC       \n","Normal    0.939          0.957          0.988     \n","Afib      0.869          0.965          0.972     \n","Other     0.947          0.977          0.993     \n","F1 Score: 0.825 ± 0.165\n","\n","=== Holdout Set Evaluation ===\n","\n","--- Evaluating Model 1 on Holdout Set ---\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-7-2f9d46536ae3>:442: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(model_path))\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Evaluating Model 2 on Holdout Set ---\n","\n","--- Evaluating Model 3 on Holdout Set ---\n","\n","--- Evaluating Model 4 on Holdout Set ---\n","\n","--- Evaluating Model 5 on Holdout Set ---\n","\n","--- Evaluating Model 6 on Holdout Set ---\n","\n","--- Evaluating Model 7 on Holdout Set ---\n","\n","--- Evaluating Model 8 on Holdout Set ---\n","\n","--- Evaluating Model 9 on Holdout Set ---\n","\n","--- Evaluating Model 10 on Holdout Set ---\n","\n","=== Holdout Set Results ===\n","Class     Sensitivity    Specificity    AUC       \n","Normal    0.939          0.967          0.991     \n","Afib      0.917          0.965          0.984     \n","Other     0.955          0.978          0.995     \n","F1 Score: 0.832 ± 0.160\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"2poFMwKvRgqR"},"execution_count":null,"outputs":[]}]}